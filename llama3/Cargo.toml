[package]
name = "llama3"
version = "0.1.0"
edition = "2021"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies]
# candle specific dependencies
candle-core = { git = "https://github.com/huggingface/candle.git", features = ["cuda"], version = "0" }
candle-nn = { git = "https://github.com/huggingface/candle.git", features = ["cuda"], version = "0" }
candle-transformers = { git = "https://github.com/huggingface/candle.git", features = ["cuda","flash-attn"], version = "0" }
tokenizers = "0.13.4"
hf-hub = "0.3.2"
# general dependencies
serde = { version = "1.0.190", features = ["serde_derive"] }
clap = { version = "4.4.7", features = ["derive"] }
anyhow = "1.0.75"
serde_json = "1.0.108"

[workspace]
members = []

[features]
default = []
accelerate = ["dep:accelerate-src", "candle/accelerate", "candle-nn/accelerate", "candle-transformers/accelerate"]
cuda = ["candle/cuda", "candle-nn/cuda", "candle-transformers/cuda", "dep:bindgen_cuda"]
cudnn = ["candle/cudnn"]
flash-attn = ["cuda", "candle-transformers/flash-attn", "dep:candle-flash-attn"]
mkl = ["dep:intel-mkl-src", "candle/mkl", "candle-nn/mkl", "candle-transformers/mkl"]
